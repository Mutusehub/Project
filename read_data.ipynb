{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Install required packages\n",
    "    !pip install ase torch_geometric\n",
    "    import torch\n",
    "    from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "    dataset = \"/content/drive/My Drive/Dataset\"\n",
    "else:\n",
    "    dataset = \"Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = f\"{dataset}/absorption_mp_data.pkl\"\n",
    "the_data = pd.read_pickle(path)\n",
    "the_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_structure = the_data[\"structure\"][1]\n",
    "for i in a_structure:\n",
    "    #print(type(i))\n",
    "    print([i.number, i.index, i.position, i.symbol])\n",
    "    '''\n",
    "    print(i.position)\n",
    "    print(i.index)\n",
    "    print(i.number)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "\n",
    "atom_0 = a_structure[0].symbol\n",
    "#, a_structure[0].position\n",
    "print(atom_0)\n",
    "#atom_1 = a_structure[1].symbol\n",
    "#, a_structure[1].position\n",
    "print(atom_1)\n",
    "atom_2 = a_structure[2].symbol\n",
    "print(atom_2)\n",
    "atoms = Atoms([atom_0, atom_2])\n",
    "\n",
    "distance = atoms.get_distance(0,1)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "list_atoms = []\n",
    "for i in a_structure:\n",
    "    a_symbol = [i.symbol, i.position]\n",
    "    list_atoms.append(a_symbol)\n",
    "print(list_atoms)\n",
    "\n",
    "\n",
    "bonds =list_atoms[0].get_bonds(list_atoms[1])\n",
    "print(bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_structure.symbols[0],(a_structure.symbols[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the_data[\"energies\"]\n",
    "#energy_0 = np.size(the_data[\"energies\"][0])\n",
    "#abs_cof = np.size(the_data[\"absorption_coefficient\"][0])\n",
    "#ima_diel = np.size(the_data[\"imag_dielectric\"][0])\n",
    "rel_diel = np.size(the_data[\"real_dielectric\"][0])\n",
    "\n",
    "'''energy_0 = the_data[\"energies\"][0]\n",
    "i = 0\n",
    "for x in energy_0:\n",
    "    i = i +1\n",
    "\n",
    "print(i)'''\n",
    "rel_diel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ase import Atoms\n",
    "from ase.neighborlist import NeighborList, natural_cutoffs\n",
    "\n",
    "# Example molecule: Water\n",
    "#atoms = Atoms('H2O', positions=[[0, 0, 0], [0, 0.76, 0.58], [0, -0.76, 0.58]])\n",
    "#atoms = Atoms(a_structure.symbols, a_structure.positions)\n",
    "atoms = a_structure\n",
    "# Step 1: Compute cutoffs for each atom (heuristic for bonding radius)\n",
    "cutoffs = natural_cutoffs(atoms)\n",
    "\n",
    "# Step 2: Build neighbor list\n",
    "nl = NeighborList(cutoffs, self_interaction=False, bothways=True)\n",
    "nl.update(atoms)\n",
    "\n",
    "# Step 3: Loop over all atoms to get bonded neighbors (edges)\n",
    "bonds = []\n",
    "for i in range(len(atoms)):\n",
    "    indices, offsets = nl.get_neighbors(i)\n",
    "    for j, offset in zip(indices, offsets):\n",
    "        if i < j:  # avoid double counting\n",
    "            distance = atoms.get_distance(i, j, mic=True)\n",
    "            bonds.append(((i, j), distance))\n",
    "\n",
    "# Display edge (bond) info\n",
    "for (i, j), dist in bonds:\n",
    "    print(f\"Bond between atom {i} ({atoms[i].symbol}) and {j} ({atoms[j].symbol}) - Distance: {dist:.2f} Å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "\n",
    "import torch\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch_geometric.data import Data\n",
    "from torch_cluster import radius_graph\n",
    "\n",
    "from e3nn import o3\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "from e3nn.nn import Gate\n",
    "from e3nn.nn.models.gate_points_2101 import Convolution, smooth_cutoff, tp_path_exists\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# format progress bar\n",
    "bar_format = '{l_bar}{bar:10}{r_bar}{bar:-10b}'\n",
    "\n",
    "\n",
    "# standard formatting for plots\n",
    "fontsize = 16\n",
    "textsize = 14\n",
    "sub = str.maketrans(\"0123456789\", \"₀₁₂₃₄₅₆₇₈₉\")\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.rcParams['mathtext.default'] = 'regular'\n",
    "plt.rcParams['xtick.bottom'] = True\n",
    "plt.rcParams['ytick.left'] = True\n",
    "plt.rcParams['font.size'] = fontsize\n",
    "plt.rcParams['axes.labelsize'] = fontsize\n",
    "plt.rcParams['xtick.labelsize'] = fontsize\n",
    "plt.rcParams['ytick.labelsize'] = fontsize\n",
    "plt.rcParams['legend.fontsize'] = textsize\n",
    "\n",
    "\n",
    "# Define custom mean squared error function\n",
    "class BandLoss(_Loss):\n",
    "    def __init__(self, size_average = None, reduce = None, reduction: str = 'mean') -> None:\n",
    "        super(BandLoss, self).__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return torch.sum(torch.pow(torch.abs(input - target)/torch.max(torch.abs(target)), 2)) \\\n",
    "               /torch.numel(target)\n",
    "\n",
    "\n",
    "class CustomCompose(torch.nn.Module):\n",
    "    def __init__(self, first, second):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "        self.irreps_in = self.first.irreps_in\n",
    "        self.irreps_out = self.second.irreps_out\n",
    "\n",
    "    def forward(self, *input):\n",
    "        x = self.first(*input)\n",
    "        self.first_out = x.clone()\n",
    "        x = self.second(x)\n",
    "        self.second_out = x.clone()\n",
    "        return x\n",
    "\n",
    "\n",
    "class Network(torch.nn.Module):\n",
    "    r\"\"\"equivariant neural network\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps_in : `e3nn.o3.Irreps` or None\n",
    "        representation of the input features\n",
    "        can be set to ``None`` if nodes don't have input features\n",
    "    irreps_hidden : `e3nn.o3.Irreps`\n",
    "        representation of the hidden features\n",
    "    irreps_out : `e3nn.o3.Irreps`\n",
    "        representation of the output features\n",
    "    irreps_node_attr : `e3nn.o3.Irreps` or None\n",
    "        representation of the nodes attributes\n",
    "        can be set to ``None`` if nodes don't have attributes\n",
    "    irreps_edge_attr : `e3nn.o3.Irreps`\n",
    "        representation of the edge attributes\n",
    "        the edge attributes are :math:`h(r) Y(\\vec r / r)`\n",
    "        where :math:`h` is a smooth function that goes to zero at ``max_radius``\n",
    "        and :math:`Y` are the spherical harmonics polynomials\n",
    "    layers : int\n",
    "        number of gates (non linearities)\n",
    "    max_radius : float\n",
    "        maximum radius for the convolution\n",
    "    number_of_basis : int\n",
    "        number of basis on which the edge length are projected\n",
    "    radial_layers : int\n",
    "        number of hidden layers in the radial fully connected network\n",
    "    radial_neurons : int\n",
    "        number of neurons in the hidden layers of the radial fully connected network\n",
    "    num_neighbors : float\n",
    "        typical number of nodes at a distance ``max_radius``\n",
    "    num_nodes : float\n",
    "        typical number of nodes in a graph\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        irreps_in,\n",
    "        irreps_out,\n",
    "        irreps_node_attr,\n",
    "        layers,\n",
    "        mul,\n",
    "        lmax,\n",
    "        max_radius,\n",
    "        number_of_basis=10,\n",
    "        radial_layers=1,\n",
    "        radial_neurons=100,\n",
    "        num_neighbors=1.,\n",
    "        num_nodes=1.,\n",
    "        reduce_output=True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.mul = mul\n",
    "        self.lmax = lmax\n",
    "        self.max_radius = max_radius\n",
    "        self.number_of_basis = number_of_basis\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.num_nodes = num_nodes\n",
    "        self.reduce_output = reduce_output\n",
    "\n",
    "        self.irreps_in = o3.Irreps(irreps_in) if irreps_in is not None else None\n",
    "        self.irreps_hidden = o3.Irreps([(self.mul, (l, p)) for l in range(lmax + 1) for p in [-1, 1]])\n",
    "        self.irreps_out = o3.Irreps(irreps_out)\n",
    "        self.irreps_node_attr = o3.Irreps(irreps_node_attr) if irreps_node_attr is not None else o3.Irreps(\"0e\")\n",
    "        self.irreps_edge_attr = o3.Irreps.spherical_harmonics(lmax)\n",
    "\n",
    "        self.input_has_node_in = (irreps_in is not None)\n",
    "        self.input_has_node_attr = (irreps_node_attr is not None)\n",
    "\n",
    "        irreps = self.irreps_in if self.irreps_in is not None else o3.Irreps(\"0e\")\n",
    "\n",
    "        act = {\n",
    "            1: torch.nn.functional.silu,\n",
    "            -1: torch.tanh,\n",
    "        }\n",
    "        act_gates = {\n",
    "            1: torch.sigmoid,\n",
    "            -1: torch.tanh,\n",
    "        }\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(layers):\n",
    "            irreps_scalars = o3.Irreps([(mul, ir) for mul, ir in self.irreps_hidden if ir.l == 0 and tp_path_exists(irreps, self.irreps_edge_attr, ir)])\n",
    "            irreps_gated = o3.Irreps([(mul, ir) for mul, ir in self.irreps_hidden if ir.l > 0 and tp_path_exists(irreps, self.irreps_edge_attr, ir)])\n",
    "            ir = \"0e\" if tp_path_exists(irreps, self.irreps_edge_attr, \"0e\") else \"0o\"\n",
    "            irreps_gates = o3.Irreps([(mul, ir) for mul, _ in irreps_gated])\n",
    "\n",
    "            gate = Gate(\n",
    "                irreps_scalars, [act[ir.p] for _, ir in irreps_scalars],  # scalar\n",
    "                irreps_gates, [act_gates[ir.p] for _, ir in irreps_gates],  # gates (scalars)\n",
    "                irreps_gated  # gated tensors\n",
    "            )\n",
    "            conv = Convolution(\n",
    "                irreps,\n",
    "                self.irreps_node_attr,\n",
    "                self.irreps_edge_attr,\n",
    "                gate.irreps_in,\n",
    "                number_of_basis,\n",
    "                radial_layers,\n",
    "                radial_neurons,\n",
    "                num_neighbors\n",
    "            )\n",
    "            irreps = gate.irreps_out\n",
    "            self.layers.append(CustomCompose(conv, gate))\n",
    "\n",
    "        self.layers.append(\n",
    "            Convolution(\n",
    "                irreps,\n",
    "                self.irreps_node_attr,\n",
    "                self.irreps_edge_attr,\n",
    "                self.irreps_out,\n",
    "                number_of_basis,\n",
    "                radial_layers,\n",
    "                radial_neurons,\n",
    "                num_neighbors\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def preprocess(self, data: Union[Data, Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
    "        if 'batch' in data:\n",
    "            batch = data['batch']\n",
    "        else:\n",
    "            batch = data['pos'].new_zeros(data['pos'].shape[0], dtype=torch.long)\n",
    "\n",
    "        if 'edge_index' in data:\n",
    "            edge_src = data['edge_index'][0]  # edge source\n",
    "            edge_dst = data['edge_index'][1]  # edge destination\n",
    "            edge_vec = data['edge_vec']\n",
    "        \n",
    "        else:\n",
    "            edge_index = radius_graph(data['pos'], self.max_radius, batch)\n",
    "            edge_src = edge_index[0]\n",
    "            edge_dst = edge_index[1]\n",
    "            edge_vec = data['pos'][edge_src] - data['pos'][edge_dst]\n",
    "\n",
    "        return batch, edge_src, edge_dst, edge_vec\n",
    "\n",
    "    def forward(self, data: Union[Data, Dict[str, torch.Tensor]]) -> torch.Tensor:\n",
    "        \"\"\"evaluate the network\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : `torch_geometric.data.Data` or dict\n",
    "            data object containing\n",
    "            - ``pos`` the position of the nodes (atoms)\n",
    "            - ``x`` the input features of the nodes, optional\n",
    "            - ``z`` the attributes of the nodes, for instance the atom type, optional\n",
    "            - ``batch`` the graph to which the node belong, optional\n",
    "        \"\"\"\n",
    "        batch, edge_src, edge_dst, edge_vec = self.preprocess(data)\n",
    "        edge_sh = o3.spherical_harmonics(self.irreps_edge_attr, edge_vec, True, normalization='component')\n",
    "        edge_length = edge_vec.norm(dim=1)\n",
    "        edge_length_embedded = soft_one_hot_linspace(\n",
    "            x=edge_length,\n",
    "            start=0.0,\n",
    "            end=self.max_radius,\n",
    "            number=self.number_of_basis,\n",
    "            basis='gaussian',\n",
    "            cutoff=False\n",
    "        ).mul(self.number_of_basis**0.5)\n",
    "        edge_attr = smooth_cutoff(edge_length / self.max_radius)[:, None] * edge_sh\n",
    "\n",
    "        if self.input_has_node_in and 'x' in data:\n",
    "            assert self.irreps_in is not None\n",
    "            x = data['x']\n",
    "        else:\n",
    "            assert self.irreps_in is None\n",
    "            x = data['pos'].new_ones((data['pos'].shape[0], 1))\n",
    "\n",
    "        if self.input_has_node_attr and 'z' in data:\n",
    "            z = data['z']\n",
    "        else:\n",
    "            assert self.irreps_node_attr == o3.Irreps(\"0e\")\n",
    "            z = data['pos'].new_ones((data['pos'].shape[0], 1))\n",
    "\n",
    "        for lay in self.layers:\n",
    "            x = lay(x, z, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "\n",
    "        if self.reduce_output:\n",
    "            return scatter(x, batch, dim=0).div(self.num_nodes**0.5)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "def visualize_layers(model):\n",
    "    layer_dst = dict(zip(['sc', 'lin1', 'tp', 'lin2'], ['gate', 'tp', 'lin2', 'gate']))\n",
    "    try: layers = model.mp.layers\n",
    "    except: layers = model.layers\n",
    "\n",
    "    num_layers = len(layers)\n",
    "    num_ops = max([len([k for k in list(layers[i].first._modules.keys()) if k not in ['fc', 'alpha']])\n",
    "                   for i in range(num_layers-1)])\n",
    "\n",
    "    fig, ax = plt.subplots(num_layers, num_ops, figsize=(14,3.5*num_layers))\n",
    "    for i in range(num_layers - 1):\n",
    "        ops = layers[i].first._modules.copy()\n",
    "        ops.pop('fc', None); ops.pop('alpha', None)\n",
    "        for j, (k, v) in enumerate(ops.items()):\n",
    "            ax[i,j].set_title(k, fontsize=textsize)\n",
    "            v.cpu().visualize(ax=ax[i,j])\n",
    "            ax[i,j].text(0.7,-0.15,'--> to ' + layer_dst[k], fontsize=textsize-2, transform=ax[i,j].transAxes)\n",
    "\n",
    "    layer_dst = dict(zip(['sc', 'lin1', 'tp', 'lin2'], ['output', 'tp', 'lin2', 'output']))\n",
    "    ops = layers[-1]._modules.copy()\n",
    "    ops.pop('fc', None); ops.pop('alpha', None)\n",
    "    for j, (k, v) in enumerate(ops.items()):\n",
    "        ax[-1,j].set_title(k, fontsize=textsize)\n",
    "        v.cpu().visualize(ax=ax[-1,j])\n",
    "        ax[-1,j].text(0.7,-0.15,'--> to ' + layer_dst[k], fontsize=textsize-2, transform=ax[-1,j].transAxes)\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "\n",
    "\n",
    "def loglinspace(rate, step, end=None):\n",
    "    t = 0\n",
    "    while end is None or t <= end:\n",
    "        yield t\n",
    "        t = int(t + 1 + step*(1 - math.exp(-t*rate/step)))\n",
    "\n",
    "        \n",
    "def evaluate(model, dataloader, loss_fn, loss_fn_mae, device):\n",
    "    model.eval()\n",
    "    loss_cumulative = 0.\n",
    "    loss_cumulative_mae = 0.\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for j, d in enumerate(dataloader):\n",
    "            d.to(device)\n",
    "            output = model(d)\n",
    "            loss = loss_fn(output, d.y).cpu()\n",
    "            loss_mae = loss_fn_mae(output, d.y).cpu()\n",
    "            loss_cumulative = loss_cumulative + loss.detach().item()\n",
    "            loss_cumulative_mae = loss_cumulative_mae + loss_mae.detach().item()\n",
    "    return loss_cumulative/len(dataloader), loss_cumulative_mae/len(dataloader)\n",
    "\n",
    "\n",
    "def train(model, optimizer, dataloader_train, dataloader_valid, loss_fn, loss_fn_mae, run_name,\n",
    "          max_iter=101, scheduler=None, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "\n",
    "    checkpoint_generator = loglinspace(0.3, 5)\n",
    "    checkpoint = next(checkpoint_generator)\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    try: model.load_state_dict(torch.load(run_name + '.torch')['state'])\n",
    "    except:\n",
    "        results = {}\n",
    "        history = []\n",
    "        s0 = 0\n",
    "    else:\n",
    "        results = torch.load(run_name + '.torch')\n",
    "        history = results['history']\n",
    "        s0 = history[-1]['step'] + 1\n",
    "\n",
    "\n",
    "    for step in range(max_iter):\n",
    "        model.train()\n",
    "        loss_cumulative = 0.\n",
    "        loss_cumulative_mae = 0.\n",
    "        \n",
    "        for j, d in tqdm(enumerate(dataloader_train), total=len(dataloader_train), bar_format=bar_format):\n",
    "            d.to(device)\n",
    "            output = model(d)\n",
    "            loss = loss_fn(output, d.y).cpu()\n",
    "            loss_mae = loss_fn_mae(output, d.y).cpu()\n",
    "            loss_cumulative = loss_cumulative + loss.detach().item()\n",
    "            loss_cumulative_mae = loss_cumulative_mae + loss_mae.detach().item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "        wall = end_time - start_time\n",
    "\n",
    "        if step == checkpoint:\n",
    "            checkpoint = next(checkpoint_generator)\n",
    "            assert checkpoint > step\n",
    "\n",
    "            valid_avg_loss = evaluate(model, dataloader_valid, loss_fn, loss_fn_mae, device)\n",
    "            train_avg_loss = evaluate(model, dataloader_train, loss_fn, loss_fn_mae, device)\n",
    "\n",
    "            history.append({\n",
    "                'step': s0 + step,\n",
    "                'wall': wall,\n",
    "                'batch': {\n",
    "                    'loss': loss.item(),\n",
    "                    'mean_abs': loss_mae.item(),\n",
    "                },\n",
    "                'valid': {\n",
    "                    'loss': valid_avg_loss[0],\n",
    "                    'mean_abs': valid_avg_loss[1],\n",
    "                },\n",
    "                'train': {\n",
    "                    'loss': train_avg_loss[0],\n",
    "                    'mean_abs': train_avg_loss[1],\n",
    "                },\n",
    "            })\n",
    "\n",
    "            results = {\n",
    "                'history': history,\n",
    "                'state': model.state_dict()\n",
    "            }\n",
    "\n",
    "            print(f\"Iteration {step+1:4d}   \" +\n",
    "                  f\"train loss = {train_avg_loss[0]:8.4f}   \" +\n",
    "                  f\"valid loss = {valid_avg_loss[0]:8.4f}   \" +\n",
    "                  f\"elapsed time = {time.strftime('%H:%M:%S', time.gmtime(wall))}\")\n",
    "            \n",
    "            weight = torch.abs(model.em_mixing.weight)/(torch.sum(torch.abs(model.em_mixing.weight), dim=1, keepdim=True)+1e-10)\n",
    "            print(weight)\n",
    "\n",
    "            with open(f'./model/{run_name}.torch', 'wb') as f:\n",
    "                torch.save(results, f)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MUTUSE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
